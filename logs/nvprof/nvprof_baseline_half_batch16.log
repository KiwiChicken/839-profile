Initializing NVTX monkey patches
Done with NVTX monkey patching
I Loading best validating checkpoint from /root/.local/share/deepspeech/checkpoints/best_dev-6489
I Loading variable from checkpoint: beta1_power
I Loading variable from checkpoint: beta2_power
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1
I Loading variable from checkpoint: global_step
I Loading variable from checkpoint: layer_1/bias
I Loading variable from checkpoint: layer_1/bias/Adam
I Loading variable from checkpoint: layer_1/bias/Adam_1
I Loading variable from checkpoint: layer_1/weights
I Loading variable from checkpoint: layer_1/weights/Adam
I Loading variable from checkpoint: layer_1/weights/Adam_1
I Loading variable from checkpoint: layer_2/bias
I Loading variable from checkpoint: layer_2/bias/Adam
I Loading variable from checkpoint: layer_2/bias/Adam_1
I Loading variable from checkpoint: layer_2/weights
I Loading variable from checkpoint: layer_2/weights/Adam
I Loading variable from checkpoint: layer_2/weights/Adam_1
I Loading variable from checkpoint: layer_3/bias
I Loading variable from checkpoint: layer_3/bias/Adam
I Loading variable from checkpoint: layer_3/bias/Adam_1
I Loading variable from checkpoint: layer_3/weights
I Loading variable from checkpoint: layer_3/weights/Adam
I Loading variable from checkpoint: layer_3/weights/Adam_1
I Loading variable from checkpoint: layer_5/bias
I Loading variable from checkpoint: layer_5/bias/Adam
I Loading variable from checkpoint: layer_5/bias/Adam_1
I Loading variable from checkpoint: layer_5/weights
I Loading variable from checkpoint: layer_5/weights/Adam
I Loading variable from checkpoint: layer_5/weights/Adam_1
I Loading variable from checkpoint: layer_6/bias
I Loading variable from checkpoint: layer_6/bias/Adam
I Loading variable from checkpoint: layer_6/bias/Adam_1
I Loading variable from checkpoint: layer_6/weights
I Loading variable from checkpoint: layer_6/weights/Adam
I Loading variable from checkpoint: layer_6/weights/Adam_1
I Loading variable from checkpoint: learning_rate
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000
Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 1 | Loss: 44.277664
Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 2 | Loss: 48.213791
Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 50.011354
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 51.467071
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 5 | Loss: 51.319641
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 6 | Loss: 52.702784
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 7 | Loss: 53.397047
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 8 | Loss: 54.038569
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 9 | Loss: 55.808168
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 10 | Loss: 56.797611
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 11 | Loss: 58.366683
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 12 | Loss: 59.205726
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 13 | Loss: 60.924178
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 14 | Loss: 61.654517
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 15 | Loss: 62.918162
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 16 | Loss: 63.998652
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 17 | Loss: 65.284733
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 18 | Loss: 67.774488
Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 19 | Loss: 68.870611
Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 20 | Loss: 69.772441
Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 21 | Loss: 71.263670
Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 22 | Loss: 72.341154
Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 23 | Loss: 73.575342
Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 24 | Loss: 74.910551
Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 25 | Loss: 75.714422
Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 26 | Loss: 76.331093
Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 27 | Loss: 77.731289
Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 28 | Loss: 78.735285
Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 29 | Loss: 79.721965
Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 30 | Loss: 80.497451
Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 31 | Loss: 82.002038
Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 32 | Loss: 82.767021
Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 33 | Loss: 84.081370
Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 34 | Loss: 85.141365
Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 35 | Loss: 86.586602
Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 36 | Loss: 87.912883
Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 37 | Loss: 89.310258
Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 38 | Loss: 90.312440
Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 39 | Loss: 91.846897
Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 40 | Loss: 92.961013
Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 41 | Loss: 94.509737
Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 42 | Loss: 96.134539
Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 43 | Loss: 97.457097
Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 44 | Loss: 98.973468
Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 45 | Loss: 100.587089
Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 46 | Loss: 102.065646
Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 47 | Loss: 103.404459
Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 48 | Loss: 104.914278
Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 49 | Loss: 106.070458
Epoch 0 |   Training | Elapsed Time: 0:00:15 | Steps: 50 | Loss: 107.479550
Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 51 | Loss: 108.995148
Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 52 | Loss: 110.570030
Epoch 0 |   Training | Elapsed Time: 0:00:16 | Steps: 53 | Loss: 112.244331
Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 54 | Loss: 113.915097
Epoch 0 |   Training | Elapsed Time: 0:00:17 | Steps: 55 | Loss: 115.702182
Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 56 | Loss: 117.276894
Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 57 | Loss: 119.330440
Epoch 0 |   Training | Elapsed Time: 0:00:18 | Steps: 58 | Loss: 120.894863
Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 59 | Loss: 122.964569
Epoch 0 |   Training | Elapsed Time: 0:00:19 | Steps: 60 | Loss: 124.803852
Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 61 | Loss: 126.737103
Epoch 0 |   Training | Elapsed Time: 0:00:20 | Steps: 62 | Loss: 128.711831
Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 63 | Loss: 130.820785
Epoch 0 |   Training | Elapsed Time: 0:00:21 | Steps: 64 | Loss: 132.843339
Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 65 | Loss: 135.205627
Epoch 0 |   Training | Elapsed Time: 0:00:22 | Steps: 66 | Loss: 137.611956
Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 67 | Loss: 140.329870
Epoch 0 |   Training | Elapsed Time: 0:00:23 | Steps: 68 | Loss: 143.432888
Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 69 | Loss: 146.273559
Epoch 0 |   Training | Elapsed Time: 0:00:24 | Steps: 69 | Loss: 146.273559
Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 1 | Loss: 42.323250 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 3 | Loss: 47.548172 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 48.890464 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 7 | Loss: 50.791969 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 9 | Loss: 53.591770 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 12 | Loss: 56.976169 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 14 | Loss: 60.470078 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 16 | Loss: 63.192742 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 18 | Loss: 65.578869 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 20 | Loss: 68.153408 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 22 | Loss: 70.096387 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 24 | Loss: 72.010848 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 26 | Loss: 73.926519 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 28 | Loss: 76.187228 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 30 | Loss: 78.618697 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 32 | Loss: 81.478222 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 34 | Loss: 83.802810 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 36 | Loss: 86.270961 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 38 | Loss: 89.472937 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 40 | Loss: 92.726245 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 42 | Loss: 96.674213 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 44 | Loss: 99.827156 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 46 | Loss: 103.109431 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 47 | Loss: 105.203815 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 48 | Loss: 107.153800 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 49 | Loss: 109.095601 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 50 | Loss: 111.148205 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 51 | Loss: 113.324482 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 52 | Loss: 115.894961 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 53 | Loss: 118.199400 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 54 | Loss: 120.651120 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 55 | Loss: 123.490120 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 56 | Loss: 126.679176 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 57 | Loss: 130.295654 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:06 | Steps: 58 | Loss: 133.809549 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:07 | Steps: 59 | Loss: 138.795844 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:07 | Steps: 59 | Loss: 138.795844 | Dataset: set/clips/half_dev.csv
I Saved new best validating model with loss 138.795844 to: /root/.local/share/deepspeech/checkpoints/best_dev-6558
--------------------------------------------------------------------------------
I FINISHED optimization in 0:00:32.963456
