Initializing NVTX monkey patches
Done with NVTX monkey patching
I Loading best validating checkpoint from /root/.local/share/deepspeech/checkpoints/best_dev-6627
I Loading variable from checkpoint: beta1_power
I Loading variable from checkpoint: beta2_power
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam
I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1
I Loading variable from checkpoint: global_step
I Loading variable from checkpoint: layer_1/bias
I Loading variable from checkpoint: layer_1/bias/Adam
I Loading variable from checkpoint: layer_1/bias/Adam_1
I Loading variable from checkpoint: layer_1/weights
I Loading variable from checkpoint: layer_1/weights/Adam
I Loading variable from checkpoint: layer_1/weights/Adam_1
I Loading variable from checkpoint: layer_2/bias
I Loading variable from checkpoint: layer_2/bias/Adam
I Loading variable from checkpoint: layer_2/bias/Adam_1
I Loading variable from checkpoint: layer_2/weights
I Loading variable from checkpoint: layer_2/weights/Adam
I Loading variable from checkpoint: layer_2/weights/Adam_1
I Loading variable from checkpoint: layer_3/bias
I Loading variable from checkpoint: layer_3/bias/Adam
I Loading variable from checkpoint: layer_3/bias/Adam_1
I Loading variable from checkpoint: layer_3/weights
I Loading variable from checkpoint: layer_3/weights/Adam
I Loading variable from checkpoint: layer_3/weights/Adam_1
I Loading variable from checkpoint: layer_5/bias
I Loading variable from checkpoint: layer_5/bias/Adam
I Loading variable from checkpoint: layer_5/bias/Adam_1
I Loading variable from checkpoint: layer_5/weights
I Loading variable from checkpoint: layer_5/weights/Adam
I Loading variable from checkpoint: layer_5/weights/Adam_1
I Loading variable from checkpoint: layer_6/bias
I Loading variable from checkpoint: layer_6/bias/Adam
I Loading variable from checkpoint: layer_6/bias/Adam_1
I Loading variable from checkpoint: layer_6/weights
I Loading variable from checkpoint: layer_6/weights/Adam
I Loading variable from checkpoint: layer_6/weights/Adam_1
I Loading variable from checkpoint: learning_rate
I STARTING Optimization
Epoch 0 |   Training | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000
Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 1 | Loss: 47.656929
Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 2 | Loss: 51.209507
Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 52.772204
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 4 | Loss: 54.464067
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 5 | Loss: 57.449557
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 6 | Loss: 60.026385
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 7 | Loss: 62.449038
Epoch 0 |   Training | Elapsed Time: 0:00:04 | Steps: 8 | Loss: 64.644827
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 9 | Loss: 68.058797
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 10 | Loss: 69.936217
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 11 | Loss: 72.389069
Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 12 | Loss: 74.952443
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 13 | Loss: 76.359211
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 14 | Loss: 78.866643
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 15 | Loss: 80.617302
Epoch 0 |   Training | Elapsed Time: 0:00:06 | Steps: 16 | Loss: 82.944402
Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 17 | Loss: 85.391166
Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 18 | Loss: 88.281386
Epoch 0 |   Training | Elapsed Time: 0:00:07 | Steps: 19 | Loss: 90.701174
Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 20 | Loss: 93.378276
Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 21 | Loss: 96.601322
Epoch 0 |   Training | Elapsed Time: 0:00:08 | Steps: 22 | Loss: 99.429963
Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 23 | Loss: 102.502252
Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 24 | Loss: 105.337206
Epoch 0 |   Training | Elapsed Time: 0:00:09 | Steps: 25 | Loss: 107.900291
Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 26 | Loss: 110.993676
Epoch 0 |   Training | Elapsed Time: 0:00:10 | Steps: 27 | Loss: 114.342557
Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 28 | Loss: 117.704219
Epoch 0 |   Training | Elapsed Time: 0:00:11 | Steps: 29 | Loss: 121.310134
Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 30 | Loss: 125.202535
Epoch 0 |   Training | Elapsed Time: 0:00:12 | Steps: 31 | Loss: 129.090201
Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 32 | Loss: 133.216821
Epoch 0 |   Training | Elapsed Time: 0:00:13 | Steps: 33 | Loss: 137.979813
Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 34 | Loss: 143.786237
Epoch 0 |   Training | Elapsed Time: 0:00:14 | Steps: 34 | Loss: 143.786237
Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 0 | Loss: 0.000000 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:01 | Steps: 1 | Loss: 46.224823 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 2 | Loss: 47.359802 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 3 | Loss: 49.352402 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 4 | Loss: 51.833147 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 6 | Loss: 56.396104 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 8 | Loss: 62.647305 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 10 | Loss: 67.611469 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 12 | Loss: 71.447924 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:02 | Steps: 14 | Loss: 75.609699 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 16 | Loss: 80.924299 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 18 | Loss: 85.719022 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 20 | Loss: 92.209093 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 21 | Loss: 96.184623 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 22 | Loss: 99.343555 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 23 | Loss: 102.633677 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 24 | Loss: 106.702500 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 25 | Loss: 110.710547 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 26 | Loss: 115.481076 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 27 | Loss: 120.259102 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 28 | Loss: 126.324871 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 29 | Loss: 133.480418 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:04 | Steps: 30 | Loss: 143.333744 | Dataset: set/clips/half_dev.csv
Epoch 0 | Validation | Elapsed Time: 0:00:05 | Steps: 30 | Loss: 143.333744 | Dataset: set/clips/half_dev.csv
I Saved new best validating model with loss 143.333744 to: /root/.local/share/deepspeech/checkpoints/best_dev-6661
--------------------------------------------------------------------------------
I FINISHED optimization in 0:00:20.645689
